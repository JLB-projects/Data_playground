{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a394005",
   "metadata": {},
   "source": [
    "# Finding Related Tags on Data Science Stack Exchange\n",
    "Using a sample of questions and their tags, we want to find out which tags are related via the proxy of being used together on a given question. For computational simplicity we limit our simultaneous tags to pairs only. \n",
    "\n",
    "This is an extension / alternative project that uses the same sample dataset as a *DataQuest* guided project. The data was pulled from the data science [Stack Exchange](https://datascience.stackexchange.com) database via SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405adc7f",
   "metadata": {},
   "source": [
    "## Preparing the Data\n",
    "First we will import the relevant modules and set up the initial dataframe with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27df200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7137af14",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id              0\n",
       "CreationDate    0\n",
       "Score           0\n",
       "ViewCount       0\n",
       "Tags            0\n",
       "AnswerCount     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data\n",
    "df = pd.read_csv(\"questions.csv\")\n",
    "\n",
    "# Drop unwanted column\n",
    "df.drop(\"FavoriteCount\", axis=1, inplace=True)\n",
    "\n",
    "# Check for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4376fd4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>Tags</th>\n",
       "      <th>AnswerCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44419</td>\n",
       "      <td>2019-01-23 09:21:13</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;data-mining&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44420</td>\n",
       "      <td>2019-01-23 09:34:01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;regression&gt;&lt;linear-regressi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44423</td>\n",
       "      <td>2019-01-23 09:58:41</td>\n",
       "      <td>2</td>\n",
       "      <td>1651</td>\n",
       "      <td>&lt;python&gt;&lt;time-series&gt;&lt;forecast&gt;&lt;forecasting&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44427</td>\n",
       "      <td>2019-01-23 10:57:09</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;scikit-learn&gt;&lt;pca&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44428</td>\n",
       "      <td>2019-01-23 11:02:15</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>&lt;dataset&gt;&lt;bigdata&gt;&lt;data&gt;&lt;speech-to-text&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id         CreationDate  Score  ViewCount  \\\n",
       "0  44419  2019-01-23 09:21:13      1         21   \n",
       "1  44420  2019-01-23 09:34:01      0         25   \n",
       "2  44423  2019-01-23 09:58:41      2       1651   \n",
       "3  44427  2019-01-23 10:57:09      0         55   \n",
       "4  44428  2019-01-23 11:02:15      0         19   \n",
       "\n",
       "                                                Tags  AnswerCount  \n",
       "0                    <machine-learning><data-mining>            0  \n",
       "1  <machine-learning><regression><linear-regressi...            0  \n",
       "2       <python><time-series><forecast><forecasting>            0  \n",
       "3              <machine-learning><scikit-learn><pca>            1  \n",
       "4           <dataset><bigdata><data><speech-to-text>            0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3badd5",
   "metadata": {},
   "source": [
    "It appears that the data is in good shape already, so the only thing left is to fix any stray data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eed4c984",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8839 entries, 0 to 8838\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Id            8839 non-null   int64 \n",
      " 1   CreationDate  8839 non-null   object\n",
      " 2   Score         8839 non-null   int64 \n",
      " 3   ViewCount     8839 non-null   int64 \n",
      " 4   Tags          8839 non-null   object\n",
      " 5   AnswerCount   8839 non-null   int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 414.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "662df9f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8839 entries, 0 to 8838\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   Id            8839 non-null   int64         \n",
      " 1   CreationDate  8839 non-null   datetime64[ns]\n",
      " 2   Score         8839 non-null   int64         \n",
      " 3   ViewCount     8839 non-null   int64         \n",
      " 4   Tags          8839 non-null   object        \n",
      " 5   AnswerCount   8839 non-null   int64         \n",
      "dtypes: datetime64[ns](1), int64(4), object(1)\n",
      "memory usage: 414.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Fix the date data type\n",
    "df[\"CreationDate\"] = pd.to_datetime(df.CreationDate)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee7116a",
   "metadata": {},
   "source": [
    "## Formatting Tags\n",
    "\n",
    "We now have a dataframe with all the columns we need, and have performed some additional cleaning in case we want to use the other columns later on.\n",
    "\n",
    "The first problem to solve is the tags column. Currently it is not very easy to extract the information we want directly, so we will separate the tags into the equivalent of dummy columns. Note we cannot use the pandas method directly to make this easy, since there are a varied number of tags in each entry. \n",
    "\n",
    "The method we will use is to create a set of the unique tags for later use, then use sklearn's *MultiLabelBinarizer()* to create our dummies since it can handle the multi-labelled entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "530b2c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each Tags entry to a list for easier processing\n",
    "df[\"Tags\"] = df.Tags.str[1:-1].str.split(\"><\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0e3d429",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>Tags</th>\n",
       "      <th>AnswerCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44419</td>\n",
       "      <td>2019-01-23 09:21:13</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>[machine-learning, data-mining]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44420</td>\n",
       "      <td>2019-01-23 09:34:01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>[machine-learning, regression, linear-regressi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44423</td>\n",
       "      <td>2019-01-23 09:58:41</td>\n",
       "      <td>2</td>\n",
       "      <td>1651</td>\n",
       "      <td>[python, time-series, forecast, forecasting]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44427</td>\n",
       "      <td>2019-01-23 10:57:09</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>[machine-learning, scikit-learn, pca]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44428</td>\n",
       "      <td>2019-01-23 11:02:15</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>[dataset, bigdata, data, speech-to-text]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id        CreationDate  Score  ViewCount  \\\n",
       "0  44419 2019-01-23 09:21:13      1         21   \n",
       "1  44420 2019-01-23 09:34:01      0         25   \n",
       "2  44423 2019-01-23 09:58:41      2       1651   \n",
       "3  44427 2019-01-23 10:57:09      0         55   \n",
       "4  44428 2019-01-23 11:02:15      0         19   \n",
       "\n",
       "                                                Tags  AnswerCount  \n",
       "0                    [machine-learning, data-mining]            0  \n",
       "1  [machine-learning, regression, linear-regressi...            0  \n",
       "2       [python, time-series, forecast, forecasting]            0  \n",
       "3              [machine-learning, scikit-learn, pca]            1  \n",
       "4           [dataset, bigdata, data, speech-to-text]            0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d0937b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "526"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect all of the unique tags into a set for potential later use\n",
    "\n",
    "unique_tags = set()\n",
    "for tags in df.Tags:\n",
    "    for tag in tags:\n",
    "        unique_tags.add(tag)\n",
    "len(unique_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d16eae0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8839, 532)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Create the Tag dummy columns\n",
    "mlb = MultiLabelBinarizer()\n",
    "dummies = pd.DataFrame(mlb.fit_transform(df[\"Tags\"]), columns=mlb.classes_)\n",
    "dummies.index = df.index\n",
    "df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d228b291",
   "metadata": {},
   "source": [
    "## Collecting the Pairs\n",
    "\n",
    "We now have our dummy columns for each individual tag occurence. Our aim is to investigate the relationship between tags though, so we need to do some more work on our data as the next step.\n",
    "\n",
    "We ideally want a paired dummy column for each possibe pair of tags occuring in the same question. Fortunately, this is achievable directly with *PolynomialFeatures()* from scikit-learn. We use this with the correct parameters and cleanup to add every possible pairing to our dataframe as a dummy column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03ce5a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>AnswerCount</th>\n",
       "      <th>.net</th>\n",
       "      <th>3d-object-detection</th>\n",
       "      <th>3d-reconstruction</th>\n",
       "      <th>ab-test</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>weighted-data</th>\n",
       "      <th>weka</th>\n",
       "      <th>wikipedia</th>\n",
       "      <th>wolfram-language</th>\n",
       "      <th>word</th>\n",
       "      <th>word-embeddings</th>\n",
       "      <th>word2vec</th>\n",
       "      <th>xboost</th>\n",
       "      <th>xgboost</th>\n",
       "      <th>yolo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44419</td>\n",
       "      <td>2019-01-23 09:21:13</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44420</td>\n",
       "      <td>2019-01-23 09:34:01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44423</td>\n",
       "      <td>2019-01-23 09:58:41</td>\n",
       "      <td>2</td>\n",
       "      <td>1651</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44427</td>\n",
       "      <td>2019-01-23 10:57:09</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44428</td>\n",
       "      <td>2019-01-23 11:02:15</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 531 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id        CreationDate  Score  ViewCount  AnswerCount  .net  \\\n",
       "0  44419 2019-01-23 09:21:13      1         21            0     0   \n",
       "1  44420 2019-01-23 09:34:01      0         25            0     0   \n",
       "2  44423 2019-01-23 09:58:41      2       1651            0     0   \n",
       "3  44427 2019-01-23 10:57:09      0         55            1     0   \n",
       "4  44428 2019-01-23 11:02:15      0         19            0     0   \n",
       "\n",
       "   3d-object-detection  3d-reconstruction  ab-test  accuracy  ...  \\\n",
       "0                    0                  0        0         0  ...   \n",
       "1                    0                  0        0         0  ...   \n",
       "2                    0                  0        0         0  ...   \n",
       "3                    0                  0        0         0  ...   \n",
       "4                    0                  0        0         0  ...   \n",
       "\n",
       "   weighted-data  weka  wikipedia  wolfram-language  word  word-embeddings  \\\n",
       "0              0     0          0                 0     0                0   \n",
       "1              0     0          0                 0     0                0   \n",
       "2              0     0          0                 0     0                0   \n",
       "3              0     0          0                 0     0                0   \n",
       "4              0     0          0                 0     0                0   \n",
       "\n",
       "   word2vec  xboost  xgboost  yolo  \n",
       "0         0       0        0     0  \n",
       "1         0       0        0     0  \n",
       "2         0       0        0     0  \n",
       "3         0       0        0     0  \n",
       "4         0       0        0     0  \n",
       "\n",
       "[5 rows x 531 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Discard the original Tags column as it is no longer needed\n",
    "df.drop(\"Tags\", inplace=True, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "175693fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Add columns indicating the presence of a specific pair of tags\n",
    "poly = PolynomialFeatures(2, include_bias=False, interaction_only=True)\n",
    "ints = poly.fit_transform(df.iloc[:, 5:])\n",
    "cols = poly.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c6829c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.net</th>\n",
       "      <th>3d-object-detection</th>\n",
       "      <th>3d-reconstruction</th>\n",
       "      <th>ab-test</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>activation</th>\n",
       "      <th>activation-function</th>\n",
       "      <th>active-learning</th>\n",
       "      <th>activity-recognition</th>\n",
       "      <th>actor-critic</th>\n",
       "      <th>...</th>\n",
       "      <th>word-embeddings word2vec</th>\n",
       "      <th>word-embeddings xboost</th>\n",
       "      <th>word-embeddings xgboost</th>\n",
       "      <th>word-embeddings yolo</th>\n",
       "      <th>word2vec xboost</th>\n",
       "      <th>word2vec xgboost</th>\n",
       "      <th>word2vec yolo</th>\n",
       "      <th>xboost xgboost</th>\n",
       "      <th>xboost yolo</th>\n",
       "      <th>xgboost yolo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 138601 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   .net  3d-object-detection  3d-reconstruction  ab-test  accuracy  \\\n",
       "0   0.0                  0.0                0.0      0.0       0.0   \n",
       "1   0.0                  0.0                0.0      0.0       0.0   \n",
       "2   0.0                  0.0                0.0      0.0       0.0   \n",
       "3   0.0                  0.0                0.0      0.0       0.0   \n",
       "4   0.0                  0.0                0.0      0.0       0.0   \n",
       "\n",
       "   activation  activation-function  active-learning  activity-recognition  \\\n",
       "0         0.0                  0.0              0.0                   0.0   \n",
       "1         0.0                  0.0              0.0                   0.0   \n",
       "2         0.0                  0.0              0.0                   0.0   \n",
       "3         0.0                  0.0              0.0                   0.0   \n",
       "4         0.0                  0.0              0.0                   0.0   \n",
       "\n",
       "   actor-critic  ...  word-embeddings word2vec  word-embeddings xboost  \\\n",
       "0           0.0  ...                       0.0                     0.0   \n",
       "1           0.0  ...                       0.0                     0.0   \n",
       "2           0.0  ...                       0.0                     0.0   \n",
       "3           0.0  ...                       0.0                     0.0   \n",
       "4           0.0  ...                       0.0                     0.0   \n",
       "\n",
       "   word-embeddings xgboost  word-embeddings yolo  word2vec xboost  \\\n",
       "0                      0.0                   0.0              0.0   \n",
       "1                      0.0                   0.0              0.0   \n",
       "2                      0.0                   0.0              0.0   \n",
       "3                      0.0                   0.0              0.0   \n",
       "4                      0.0                   0.0              0.0   \n",
       "\n",
       "   word2vec xgboost  word2vec yolo  xboost xgboost  xboost yolo  xgboost yolo  \n",
       "0               0.0            0.0             0.0          0.0           0.0  \n",
       "1               0.0            0.0             0.0          0.0           0.0  \n",
       "2               0.0            0.0             0.0          0.0           0.0  \n",
       "3               0.0            0.0             0.0          0.0           0.0  \n",
       "4               0.0            0.0             0.0          0.0           0.0  \n",
       "\n",
       "[5 rows x 138601 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_df = pd.DataFrame(ints, columns=cols)\n",
    "int_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8912dd",
   "metadata": {},
   "source": [
    "That's a lot of columns. We now have a dummy column for every possible pairing of tags and have removed the other columns for now to make the rest of our analysis simpler. \n",
    "\n",
    "## Getting the Frequencies\n",
    "\n",
    "We only need the total frequency of each pairing from this point, so we convert our massive dataframe into a series as well via a sum. The output of the previous function kept our individual tags as columns which we no longer need. We will remove these, and also filter the resulting series to remove any pairings of tags that don't actually occur in the sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3f1ed11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0       4565\n",
       "2.0       1261\n",
       "3.0        652\n",
       "4.0        357\n",
       "5.0        251\n",
       "          ... \n",
       "493.0        1\n",
       "1055.0       1\n",
       "77.0         1\n",
       "224.0        1\n",
       "105.0        1\n",
       "Length: 160, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum the columns (tag pairings)\n",
    "sums = int_df.sum()\n",
    "sums.index = cols\n",
    "\n",
    "# Remove pairings that have no actual occurences in the sample\n",
    "reduced_sums = sums[sums > 0]\n",
    "reduced_sums.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3e46329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the individual tag columns since we only care about pairings now\n",
    "int_sums = reduced_sums.drop(list(unique_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d8c01f",
   "metadata": {},
   "source": [
    "We want to create a final dataframe that contains a row for each pair of tags, listing the total number of occurences together as well as separately. The first step is to create a series of frequencies for the individual tags, and convert our paired tags series to a dataframe ready for more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15107e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ".net                     1\n",
       "3d-object-detection      1\n",
       "3d-reconstruction        9\n",
       "ab-test                  6\n",
       "accuracy                89\n",
       "activation               1\n",
       "activation-function     44\n",
       "active-learning          4\n",
       "activity-recognition     5\n",
       "actor-critic            21\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect the total occurences of every individual tag using the original dataframe\n",
    "tag_counts = df.iloc[:, 5:].sum()\n",
    "tag_counts.index = df.iloc[:, 5:].columns\n",
    "tag_counts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d8e209a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions_with_both</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.net machine-learning</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3d-object-detection computer-vision</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3d-object-detection deep-learning</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3d-object-detection kitti-dataset</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3d-reconstruction cloud</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Questions_with_both\n",
       ".net machine-learning                                1.0\n",
       "3d-object-detection computer-vision                  1.0\n",
       "3d-object-detection deep-learning                    1.0\n",
       "3d-object-detection kitti-dataset                    1.0\n",
       "3d-reconstruction cloud                              1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the final dataframe by first adding the pair counts from earlier\n",
    "final = pd.DataFrame()\n",
    "final[\"Questions_with_both\"] = int_sums\n",
    "final.index = int_sums.index\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f37e0f9",
   "metadata": {},
   "source": [
    "## Combining The Data\n",
    "\n",
    "Now we want to add the individual tags as columns to our dataframe for clarity and future analysis. The pairs currently exist in the index and are separated by a space, which makes it easy to extract the individual tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0918f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions_with_both</th>\n",
       "      <th>Tag_1</th>\n",
       "      <th>Tag_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.net machine-learning</th>\n",
       "      <td>1.0</td>\n",
       "      <td>.net</td>\n",
       "      <td>machine-learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3d-object-detection computer-vision</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3d-object-detection</td>\n",
       "      <td>computer-vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3d-object-detection deep-learning</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3d-object-detection</td>\n",
       "      <td>deep-learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3d-object-detection kitti-dataset</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3d-object-detection</td>\n",
       "      <td>kitti-dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3d-reconstruction cloud</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3d-reconstruction</td>\n",
       "      <td>cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visualization wolfram-language</th>\n",
       "      <td>2.0</td>\n",
       "      <td>visualization</td>\n",
       "      <td>wolfram-language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visualization word2vec</th>\n",
       "      <td>1.0</td>\n",
       "      <td>visualization</td>\n",
       "      <td>word2vec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted-data xgboost</th>\n",
       "      <td>2.0</td>\n",
       "      <td>weighted-data</td>\n",
       "      <td>xgboost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word word-embeddings</th>\n",
       "      <td>1.0</td>\n",
       "      <td>word</td>\n",
       "      <td>word-embeddings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word-embeddings word2vec</th>\n",
       "      <td>35.0</td>\n",
       "      <td>word-embeddings</td>\n",
       "      <td>word2vec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7947 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Questions_with_both                Tag_1  \\\n",
       ".net machine-learning                                1.0                 .net   \n",
       "3d-object-detection computer-vision                  1.0  3d-object-detection   \n",
       "3d-object-detection deep-learning                    1.0  3d-object-detection   \n",
       "3d-object-detection kitti-dataset                    1.0  3d-object-detection   \n",
       "3d-reconstruction cloud                              1.0    3d-reconstruction   \n",
       "...                                                  ...                  ...   \n",
       "visualization wolfram-language                       2.0        visualization   \n",
       "visualization word2vec                               1.0        visualization   \n",
       "weighted-data xgboost                                2.0        weighted-data   \n",
       "word word-embeddings                                 1.0                 word   \n",
       "word-embeddings word2vec                            35.0      word-embeddings   \n",
       "\n",
       "                                                Tag_2  \n",
       ".net machine-learning                machine-learning  \n",
       "3d-object-detection computer-vision   computer-vision  \n",
       "3d-object-detection deep-learning       deep-learning  \n",
       "3d-object-detection kitti-dataset       kitti-dataset  \n",
       "3d-reconstruction cloud                         cloud  \n",
       "...                                               ...  \n",
       "visualization wolfram-language       wolfram-language  \n",
       "visualization word2vec                       word2vec  \n",
       "weighted-data xgboost                         xgboost  \n",
       "word word-embeddings                  word-embeddings  \n",
       "word-embeddings word2vec                     word2vec  \n",
       "\n",
       "[7947 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the individual tags from the index\n",
    "final[\"Tag_1\"] = final.index.map(lambda x: x.split()[0])\n",
    "final[\"Tag_2\"] = final.index.map(lambda x: x.split()[1])\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bce963",
   "metadata": {},
   "source": [
    "Similarly we now want to add the individual tag frequencies to the dataframe. We need to give our series of tag frequencies a name before we are allowed to use it in a merge. We merge twice, joining on each tag to get the correct counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e628c8cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions_with_both</th>\n",
       "      <th>Tag_1</th>\n",
       "      <th>Tag_2</th>\n",
       "      <th>Tag_counts_x</th>\n",
       "      <th>Tag_counts_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.net machine-learning</th>\n",
       "      <td>1.0</td>\n",
       "      <td>.net</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>1</td>\n",
       "      <td>2693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3d-reconstruction machine-learning</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3d-reconstruction</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>9</td>\n",
       "      <td>2693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy machine-learning</th>\n",
       "      <td>29.0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>89</td>\n",
       "      <td>2693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activation-function machine-learning</th>\n",
       "      <td>10.0</td>\n",
       "      <td>activation-function</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>44</td>\n",
       "      <td>2693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>active-learning machine-learning</th>\n",
       "      <td>4.0</td>\n",
       "      <td>active-learning</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>4</td>\n",
       "      <td>2693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nlp stemming</th>\n",
       "      <td>1.0</td>\n",
       "      <td>nlp</td>\n",
       "      <td>stemming</td>\n",
       "      <td>493</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nltk stemming</th>\n",
       "      <td>1.0</td>\n",
       "      <td>nltk</td>\n",
       "      <td>stemming</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python spyder</th>\n",
       "      <td>1.0</td>\n",
       "      <td>python</td>\n",
       "      <td>spyder</td>\n",
       "      <td>1814</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pytorch pytorch-geometric</th>\n",
       "      <td>1.0</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch-geometric</td>\n",
       "      <td>175</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pytorch summarunner-architecture</th>\n",
       "      <td>1.0</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>summarunner-architecture</td>\n",
       "      <td>175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7947 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Questions_with_both  \\\n",
       ".net machine-learning                                 1.0   \n",
       "3d-reconstruction machine-learning                    4.0   \n",
       "accuracy machine-learning                            29.0   \n",
       "activation-function machine-learning                 10.0   \n",
       "active-learning machine-learning                      4.0   \n",
       "...                                                   ...   \n",
       "nlp stemming                                          1.0   \n",
       "nltk stemming                                         1.0   \n",
       "python spyder                                         1.0   \n",
       "pytorch pytorch-geometric                             1.0   \n",
       "pytorch summarunner-architecture                      1.0   \n",
       "\n",
       "                                                    Tag_1  \\\n",
       ".net machine-learning                                .net   \n",
       "3d-reconstruction machine-learning      3d-reconstruction   \n",
       "accuracy machine-learning                        accuracy   \n",
       "activation-function machine-learning  activation-function   \n",
       "active-learning machine-learning          active-learning   \n",
       "...                                                   ...   \n",
       "nlp stemming                                          nlp   \n",
       "nltk stemming                                        nltk   \n",
       "python spyder                                      python   \n",
       "pytorch pytorch-geometric                         pytorch   \n",
       "pytorch summarunner-architecture                  pytorch   \n",
       "\n",
       "                                                         Tag_2  Tag_counts_x  \\\n",
       ".net machine-learning                         machine-learning             1   \n",
       "3d-reconstruction machine-learning            machine-learning             9   \n",
       "accuracy machine-learning                     machine-learning            89   \n",
       "activation-function machine-learning          machine-learning            44   \n",
       "active-learning machine-learning              machine-learning             4   \n",
       "...                                                        ...           ...   \n",
       "nlp stemming                                          stemming           493   \n",
       "nltk stemming                                         stemming            43   \n",
       "python spyder                                           spyder          1814   \n",
       "pytorch pytorch-geometric                    pytorch-geometric           175   \n",
       "pytorch summarunner-architecture      summarunner-architecture           175   \n",
       "\n",
       "                                      Tag_counts_y  \n",
       ".net machine-learning                         2693  \n",
       "3d-reconstruction machine-learning            2693  \n",
       "accuracy machine-learning                     2693  \n",
       "activation-function machine-learning          2693  \n",
       "active-learning machine-learning              2693  \n",
       "...                                            ...  \n",
       "nlp stemming                                     2  \n",
       "nltk stemming                                    2  \n",
       "python spyder                                    1  \n",
       "pytorch pytorch-geometric                        2  \n",
       "pytorch summarunner-architecture                 1  \n",
       "\n",
       "[7947 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Name the tag counts data\n",
    "tag_counts.name = \"Tag_counts\"\n",
    "\n",
    "# Merge to create two new columns of tag counts for each pair\n",
    "final = final.merge(tag_counts, left_on=\"Tag_1\", right_index=True)\n",
    "final = final.merge(tag_counts, left_on=\"Tag_2\", right_index=True)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4a7868b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions_with_both</th>\n",
       "      <th>Tag_1</th>\n",
       "      <th>Tag_2</th>\n",
       "      <th>Tag_1_Count</th>\n",
       "      <th>Tag_2_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>machine-learning python</th>\n",
       "      <td>499</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>python</td>\n",
       "      <td>2693</td>\n",
       "      <td>1814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deep-learning machine-learning</th>\n",
       "      <td>429</td>\n",
       "      <td>deep-learning</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>1220</td>\n",
       "      <td>2693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine-learning neural-network</th>\n",
       "      <td>366</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>neural-network</td>\n",
       "      <td>2693</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deep-learning neural-network</th>\n",
       "      <td>305</td>\n",
       "      <td>deep-learning</td>\n",
       "      <td>neural-network</td>\n",
       "      <td>1220</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keras python</th>\n",
       "      <td>280</td>\n",
       "      <td>keras</td>\n",
       "      <td>python</td>\n",
       "      <td>935</td>\n",
       "      <td>1814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classification machine-learning</th>\n",
       "      <td>259</td>\n",
       "      <td>classification</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>685</td>\n",
       "      <td>2693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keras tensorflow</th>\n",
       "      <td>256</td>\n",
       "      <td>keras</td>\n",
       "      <td>tensorflow</td>\n",
       "      <td>935</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deep-learning keras</th>\n",
       "      <td>247</td>\n",
       "      <td>deep-learning</td>\n",
       "      <td>keras</td>\n",
       "      <td>1220</td>\n",
       "      <td>935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pandas python</th>\n",
       "      <td>244</td>\n",
       "      <td>pandas</td>\n",
       "      <td>python</td>\n",
       "      <td>354</td>\n",
       "      <td>1814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keras neural-network</th>\n",
       "      <td>235</td>\n",
       "      <td>keras</td>\n",
       "      <td>neural-network</td>\n",
       "      <td>935</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python scikit-learn</th>\n",
       "      <td>235</td>\n",
       "      <td>python</td>\n",
       "      <td>scikit-learn</td>\n",
       "      <td>1814</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keras machine-learning</th>\n",
       "      <td>195</td>\n",
       "      <td>keras</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>935</td>\n",
       "      <td>2693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine-learning scikit-learn</th>\n",
       "      <td>188</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>scikit-learn</td>\n",
       "      <td>2693</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python tensorflow</th>\n",
       "      <td>167</td>\n",
       "      <td>python</td>\n",
       "      <td>tensorflow</td>\n",
       "      <td>1814</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn deep-learning</th>\n",
       "      <td>160</td>\n",
       "      <td>cnn</td>\n",
       "      <td>deep-learning</td>\n",
       "      <td>489</td>\n",
       "      <td>1220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deep-learning python</th>\n",
       "      <td>160</td>\n",
       "      <td>deep-learning</td>\n",
       "      <td>python</td>\n",
       "      <td>1220</td>\n",
       "      <td>1814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine-learning machine-learning-model</th>\n",
       "      <td>139</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>machine-learning-model</td>\n",
       "      <td>2693</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neural-network python</th>\n",
       "      <td>137</td>\n",
       "      <td>neural-network</td>\n",
       "      <td>python</td>\n",
       "      <td>1055</td>\n",
       "      <td>1814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deep-learning tensorflow</th>\n",
       "      <td>136</td>\n",
       "      <td>deep-learning</td>\n",
       "      <td>tensorflow</td>\n",
       "      <td>1220</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keras lstm</th>\n",
       "      <td>133</td>\n",
       "      <td>keras</td>\n",
       "      <td>lstm</td>\n",
       "      <td>935</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine-learning time-series</th>\n",
       "      <td>131</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>time-series</td>\n",
       "      <td>2693</td>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn machine-learning</th>\n",
       "      <td>124</td>\n",
       "      <td>cnn</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>489</td>\n",
       "      <td>2693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine-learning predictive-modeling</th>\n",
       "      <td>123</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>predictive-modeling</td>\n",
       "      <td>2693</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine-learning regression</th>\n",
       "      <td>119</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>regression</td>\n",
       "      <td>2693</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn neural-network</th>\n",
       "      <td>118</td>\n",
       "      <td>cnn</td>\n",
       "      <td>neural-network</td>\n",
       "      <td>489</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Questions_with_both  \\\n",
       "machine-learning python                                  499   \n",
       "deep-learning machine-learning                           429   \n",
       "machine-learning neural-network                          366   \n",
       "deep-learning neural-network                             305   \n",
       "keras python                                             280   \n",
       "classification machine-learning                          259   \n",
       "keras tensorflow                                         256   \n",
       "deep-learning keras                                      247   \n",
       "pandas python                                            244   \n",
       "keras neural-network                                     235   \n",
       "python scikit-learn                                      235   \n",
       "keras machine-learning                                   195   \n",
       "machine-learning scikit-learn                            188   \n",
       "python tensorflow                                        167   \n",
       "cnn deep-learning                                        160   \n",
       "deep-learning python                                     160   \n",
       "machine-learning machine-learning-model                  139   \n",
       "neural-network python                                    137   \n",
       "deep-learning tensorflow                                 136   \n",
       "keras lstm                                               133   \n",
       "machine-learning time-series                             131   \n",
       "cnn machine-learning                                     124   \n",
       "machine-learning predictive-modeling                     123   \n",
       "machine-learning regression                              119   \n",
       "cnn neural-network                                       118   \n",
       "\n",
       "                                                    Tag_1  \\\n",
       "machine-learning python                  machine-learning   \n",
       "deep-learning machine-learning              deep-learning   \n",
       "machine-learning neural-network          machine-learning   \n",
       "deep-learning neural-network                deep-learning   \n",
       "keras python                                        keras   \n",
       "classification machine-learning            classification   \n",
       "keras tensorflow                                    keras   \n",
       "deep-learning keras                         deep-learning   \n",
       "pandas python                                      pandas   \n",
       "keras neural-network                                keras   \n",
       "python scikit-learn                                python   \n",
       "keras machine-learning                              keras   \n",
       "machine-learning scikit-learn            machine-learning   \n",
       "python tensorflow                                  python   \n",
       "cnn deep-learning                                     cnn   \n",
       "deep-learning python                        deep-learning   \n",
       "machine-learning machine-learning-model  machine-learning   \n",
       "neural-network python                      neural-network   \n",
       "deep-learning tensorflow                    deep-learning   \n",
       "keras lstm                                          keras   \n",
       "machine-learning time-series             machine-learning   \n",
       "cnn machine-learning                                  cnn   \n",
       "machine-learning predictive-modeling     machine-learning   \n",
       "machine-learning regression              machine-learning   \n",
       "cnn neural-network                                    cnn   \n",
       "\n",
       "                                                          Tag_2  Tag_1_Count  \\\n",
       "machine-learning python                                  python         2693   \n",
       "deep-learning machine-learning                 machine-learning         1220   \n",
       "machine-learning neural-network                  neural-network         2693   \n",
       "deep-learning neural-network                     neural-network         1220   \n",
       "keras python                                             python          935   \n",
       "classification machine-learning                machine-learning          685   \n",
       "keras tensorflow                                     tensorflow          935   \n",
       "deep-learning keras                                       keras         1220   \n",
       "pandas python                                            python          354   \n",
       "keras neural-network                             neural-network          935   \n",
       "python scikit-learn                                scikit-learn         1814   \n",
       "keras machine-learning                         machine-learning          935   \n",
       "machine-learning scikit-learn                      scikit-learn         2693   \n",
       "python tensorflow                                    tensorflow         1814   \n",
       "cnn deep-learning                                 deep-learning          489   \n",
       "deep-learning python                                     python         1220   \n",
       "machine-learning machine-learning-model  machine-learning-model         2693   \n",
       "neural-network python                                    python         1055   \n",
       "deep-learning tensorflow                             tensorflow         1220   \n",
       "keras lstm                                                 lstm          935   \n",
       "machine-learning time-series                        time-series         2693   \n",
       "cnn machine-learning                           machine-learning          489   \n",
       "machine-learning predictive-modeling        predictive-modeling         2693   \n",
       "machine-learning regression                          regression         2693   \n",
       "cnn neural-network                               neural-network          489   \n",
       "\n",
       "                                         Tag_2_Count  \n",
       "machine-learning python                         1814  \n",
       "deep-learning machine-learning                  2693  \n",
       "machine-learning neural-network                 1055  \n",
       "deep-learning neural-network                    1055  \n",
       "keras python                                    1814  \n",
       "classification machine-learning                 2693  \n",
       "keras tensorflow                                 584  \n",
       "deep-learning keras                              935  \n",
       "pandas python                                   1814  \n",
       "keras neural-network                            1055  \n",
       "python scikit-learn                              540  \n",
       "keras machine-learning                          2693  \n",
       "machine-learning scikit-learn                    540  \n",
       "python tensorflow                                584  \n",
       "cnn deep-learning                               1220  \n",
       "deep-learning python                            1814  \n",
       "machine-learning machine-learning-model          224  \n",
       "neural-network python                           1814  \n",
       "deep-learning tensorflow                         584  \n",
       "keras lstm                                       402  \n",
       "machine-learning time-series                     466  \n",
       "cnn machine-learning                            2693  \n",
       "machine-learning predictive-modeling             265  \n",
       "machine-learning regression                      347  \n",
       "cnn neural-network                              1055  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the final columns\n",
    "final.columns = [\"Questions_with_both\", \"Tag_1\", \"Tag_2\", \"Tag_1_Count\", \"Tag_2_Count\"]\n",
    "\n",
    "# Fix the column type\n",
    "final[\"Questions_with_both\"] = final.Questions_with_both.astype(\"int\")\n",
    "\n",
    "# Sort by number of questions for each pairing\n",
    "final.sort_values(\"Questions_with_both\", ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dedceb",
   "metadata": {},
   "source": [
    "## Investigating Tag Relationships\n",
    "\n",
    "After some cleaning of column names and data types, we have a reasonable final dataframe that we can use for our analysis. From here we have some options. We could sort by the *Questions_with_both* column as above, and find out which pairs are most commonly used together, but this is heavily biased towards tags that are both popular individually. While this isn't a terrible metric, we can try and create a new one that measures how often tags are used together in a more normalised way. \n",
    "\n",
    "We will consider the following idea: \n",
    "- Find the minimum frequency of the two involved tags.\n",
    "- Divide the *Questions_with_both* value by this number to get the proportion of tag uses that involve a specific pair.\n",
    "- Multiply by 100 because it looks nicer.\n",
    "\n",
    "A motivation for this is the example of niche topics. Consider a fairly rare tag that isn't used very often: In the original metric, we would rate any pairing of this tag with another incredibly low, as the absolute number of questions the pair appears in is capped by the unpopular tag's frequency. Instead, we use the tag's low frequency as the denominator and compute the % of questions that a given pairing appeared in. This way an unpopular tag can still score highly on interaction with another tag despite its low usage rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0de95492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions_with_both</th>\n",
       "      <th>Tag_1</th>\n",
       "      <th>Tag_2</th>\n",
       "      <th>Tag_1_Count</th>\n",
       "      <th>Tag_2_Count</th>\n",
       "      <th>Interaction_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.net machine-learning</th>\n",
       "      <td>1</td>\n",
       "      <td>.net</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>1</td>\n",
       "      <td>2693</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dplyr r</th>\n",
       "      <td>6</td>\n",
       "      <td>dplyr</td>\n",
       "      <td>r</td>\n",
       "      <td>6</td>\n",
       "      <td>268</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exploitation reinforcement-learning</th>\n",
       "      <td>1</td>\n",
       "      <td>exploitation</td>\n",
       "      <td>reinforcement-learning</td>\n",
       "      <td>1</td>\n",
       "      <td>203</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dynamic-programming reinforcement-learning</th>\n",
       "      <td>3</td>\n",
       "      <td>dynamic-programming</td>\n",
       "      <td>reinforcement-learning</td>\n",
       "      <td>3</td>\n",
       "      <td>203</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discounted-reward reinforcement-learning</th>\n",
       "      <td>5</td>\n",
       "      <td>discounted-reward</td>\n",
       "      <td>reinforcement-learning</td>\n",
       "      <td>5</td>\n",
       "      <td>203</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs231n gradient-descent</th>\n",
       "      <td>1</td>\n",
       "      <td>cs231n</td>\n",
       "      <td>gradient-descent</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cause-effect-relations data-mining</th>\n",
       "      <td>1</td>\n",
       "      <td>cause-effect-relations</td>\n",
       "      <td>data-mining</td>\n",
       "      <td>1</td>\n",
       "      <td>217</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neural-network rdkit</th>\n",
       "      <td>1</td>\n",
       "      <td>neural-network</td>\n",
       "      <td>rdkit</td>\n",
       "      <td>1055</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anaconda rdkit</th>\n",
       "      <td>1</td>\n",
       "      <td>anaconda</td>\n",
       "      <td>rdkit</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activation rdkit</th>\n",
       "      <td>1</td>\n",
       "      <td>activation</td>\n",
       "      <td>rdkit</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activation anaconda</th>\n",
       "      <td>1</td>\n",
       "      <td>activation</td>\n",
       "      <td>anaconda</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gru time-series</th>\n",
       "      <td>1</td>\n",
       "      <td>gru</td>\n",
       "      <td>time-series</td>\n",
       "      <td>1</td>\n",
       "      <td>466</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rdkit tensorflow</th>\n",
       "      <td>1</td>\n",
       "      <td>rdkit</td>\n",
       "      <td>tensorflow</td>\n",
       "      <td>1</td>\n",
       "      <td>584</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google-prediction-api tensorflow</th>\n",
       "      <td>2</td>\n",
       "      <td>google-prediction-api</td>\n",
       "      <td>tensorflow</td>\n",
       "      <td>2</td>\n",
       "      <td>584</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activation tensorflow</th>\n",
       "      <td>1</td>\n",
       "      <td>activation</td>\n",
       "      <td>tensorflow</td>\n",
       "      <td>1</td>\n",
       "      <td>584</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proximal-svm svm</th>\n",
       "      <td>1</td>\n",
       "      <td>proximal-svm</td>\n",
       "      <td>svm</td>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>libsvm svm</th>\n",
       "      <td>1</td>\n",
       "      <td>libsvm</td>\n",
       "      <td>svm</td>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>least-squares-svm svm</th>\n",
       "      <td>1</td>\n",
       "      <td>least-squares-svm</td>\n",
       "      <td>svm</td>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hog svm</th>\n",
       "      <td>1</td>\n",
       "      <td>hog</td>\n",
       "      <td>svm</td>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apache-nifi data-cleaning</th>\n",
       "      <td>1</td>\n",
       "      <td>apache-nifi</td>\n",
       "      <td>data-cleaning</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ggplot2 r</th>\n",
       "      <td>3</td>\n",
       "      <td>ggplot2</td>\n",
       "      <td>r</td>\n",
       "      <td>3</td>\n",
       "      <td>268</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c++ rnn</th>\n",
       "      <td>1</td>\n",
       "      <td>c++</td>\n",
       "      <td>rnn</td>\n",
       "      <td>1</td>\n",
       "      <td>149</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hurdle-model r</th>\n",
       "      <td>1</td>\n",
       "      <td>hurdle-model</td>\n",
       "      <td>r</td>\n",
       "      <td>1</td>\n",
       "      <td>268</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python statsmodels</th>\n",
       "      <td>1</td>\n",
       "      <td>python</td>\n",
       "      <td>statsmodels</td>\n",
       "      <td>1814</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arima statsmodels</th>\n",
       "      <td>1</td>\n",
       "      <td>arima</td>\n",
       "      <td>statsmodels</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Questions_with_both  \\\n",
       ".net machine-learning                                         1   \n",
       "dplyr r                                                       6   \n",
       "exploitation reinforcement-learning                           1   \n",
       "dynamic-programming reinforcement-learning                    3   \n",
       "discounted-reward reinforcement-learning                      5   \n",
       "cs231n gradient-descent                                       1   \n",
       "cause-effect-relations data-mining                            1   \n",
       "neural-network rdkit                                          1   \n",
       "anaconda rdkit                                                1   \n",
       "activation rdkit                                              1   \n",
       "activation anaconda                                           1   \n",
       "gru time-series                                               1   \n",
       "rdkit tensorflow                                              1   \n",
       "google-prediction-api tensorflow                              2   \n",
       "activation tensorflow                                         1   \n",
       "proximal-svm svm                                              1   \n",
       "libsvm svm                                                    1   \n",
       "least-squares-svm svm                                         1   \n",
       "hog svm                                                       1   \n",
       "apache-nifi data-cleaning                                     1   \n",
       "ggplot2 r                                                     3   \n",
       "c++ rnn                                                       1   \n",
       "hurdle-model r                                                1   \n",
       "python statsmodels                                            1   \n",
       "arima statsmodels                                             1   \n",
       "\n",
       "                                                             Tag_1  \\\n",
       ".net machine-learning                                         .net   \n",
       "dplyr r                                                      dplyr   \n",
       "exploitation reinforcement-learning                   exploitation   \n",
       "dynamic-programming reinforcement-learning     dynamic-programming   \n",
       "discounted-reward reinforcement-learning         discounted-reward   \n",
       "cs231n gradient-descent                                     cs231n   \n",
       "cause-effect-relations data-mining          cause-effect-relations   \n",
       "neural-network rdkit                                neural-network   \n",
       "anaconda rdkit                                            anaconda   \n",
       "activation rdkit                                        activation   \n",
       "activation anaconda                                     activation   \n",
       "gru time-series                                                gru   \n",
       "rdkit tensorflow                                             rdkit   \n",
       "google-prediction-api tensorflow             google-prediction-api   \n",
       "activation tensorflow                                   activation   \n",
       "proximal-svm svm                                      proximal-svm   \n",
       "libsvm svm                                                  libsvm   \n",
       "least-squares-svm svm                            least-squares-svm   \n",
       "hog svm                                                        hog   \n",
       "apache-nifi data-cleaning                              apache-nifi   \n",
       "ggplot2 r                                                  ggplot2   \n",
       "c++ rnn                                                        c++   \n",
       "hurdle-model r                                        hurdle-model   \n",
       "python statsmodels                                          python   \n",
       "arima statsmodels                                            arima   \n",
       "\n",
       "                                                             Tag_2  \\\n",
       ".net machine-learning                             machine-learning   \n",
       "dplyr r                                                          r   \n",
       "exploitation reinforcement-learning         reinforcement-learning   \n",
       "dynamic-programming reinforcement-learning  reinforcement-learning   \n",
       "discounted-reward reinforcement-learning    reinforcement-learning   \n",
       "cs231n gradient-descent                           gradient-descent   \n",
       "cause-effect-relations data-mining                     data-mining   \n",
       "neural-network rdkit                                         rdkit   \n",
       "anaconda rdkit                                               rdkit   \n",
       "activation rdkit                                             rdkit   \n",
       "activation anaconda                                       anaconda   \n",
       "gru time-series                                        time-series   \n",
       "rdkit tensorflow                                        tensorflow   \n",
       "google-prediction-api tensorflow                        tensorflow   \n",
       "activation tensorflow                                   tensorflow   \n",
       "proximal-svm svm                                               svm   \n",
       "libsvm svm                                                     svm   \n",
       "least-squares-svm svm                                          svm   \n",
       "hog svm                                                        svm   \n",
       "apache-nifi data-cleaning                            data-cleaning   \n",
       "ggplot2 r                                                        r   \n",
       "c++ rnn                                                        rnn   \n",
       "hurdle-model r                                                   r   \n",
       "python statsmodels                                     statsmodels   \n",
       "arima statsmodels                                      statsmodels   \n",
       "\n",
       "                                            Tag_1_Count  Tag_2_Count  \\\n",
       ".net machine-learning                                 1         2693   \n",
       "dplyr r                                               6          268   \n",
       "exploitation reinforcement-learning                   1          203   \n",
       "dynamic-programming reinforcement-learning            3          203   \n",
       "discounted-reward reinforcement-learning              5          203   \n",
       "cs231n gradient-descent                               1           98   \n",
       "cause-effect-relations data-mining                    1          217   \n",
       "neural-network rdkit                               1055            1   \n",
       "anaconda rdkit                                       20            1   \n",
       "activation rdkit                                      1            1   \n",
       "activation anaconda                                   1           20   \n",
       "gru time-series                                       1          466   \n",
       "rdkit tensorflow                                      1          584   \n",
       "google-prediction-api tensorflow                      2          584   \n",
       "activation tensorflow                                 1          584   \n",
       "proximal-svm svm                                      1          136   \n",
       "libsvm svm                                            1          136   \n",
       "least-squares-svm svm                                 1          136   \n",
       "hog svm                                               1          136   \n",
       "apache-nifi data-cleaning                             1          157   \n",
       "ggplot2 r                                             3          268   \n",
       "c++ rnn                                               1          149   \n",
       "hurdle-model r                                        1          268   \n",
       "python statsmodels                                 1814            1   \n",
       "arima statsmodels                                    11            1   \n",
       "\n",
       "                                            Interaction_score  \n",
       ".net machine-learning                                   100.0  \n",
       "dplyr r                                                 100.0  \n",
       "exploitation reinforcement-learning                     100.0  \n",
       "dynamic-programming reinforcement-learning              100.0  \n",
       "discounted-reward reinforcement-learning                100.0  \n",
       "cs231n gradient-descent                                 100.0  \n",
       "cause-effect-relations data-mining                      100.0  \n",
       "neural-network rdkit                                    100.0  \n",
       "anaconda rdkit                                          100.0  \n",
       "activation rdkit                                        100.0  \n",
       "activation anaconda                                     100.0  \n",
       "gru time-series                                         100.0  \n",
       "rdkit tensorflow                                        100.0  \n",
       "google-prediction-api tensorflow                        100.0  \n",
       "activation tensorflow                                   100.0  \n",
       "proximal-svm svm                                        100.0  \n",
       "libsvm svm                                              100.0  \n",
       "least-squares-svm svm                                   100.0  \n",
       "hog svm                                                 100.0  \n",
       "apache-nifi data-cleaning                               100.0  \n",
       "ggplot2 r                                               100.0  \n",
       "c++ rnn                                                 100.0  \n",
       "hurdle-model r                                          100.0  \n",
       "python statsmodels                                      100.0  \n",
       "arima statsmodels                                       100.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def int_scorer(row):\n",
    "    count = np.min([row[\"Tag_1_Count\"], row[\"Tag_2_Count\"]])\n",
    "    score = 100 * row[\"Questions_with_both\"] / count\n",
    "    return round(score, 2)\n",
    "\n",
    "# Add the new column \n",
    "final[\"Interaction_score\"] = final.apply(int_scorer, axis=1)\n",
    "final.sort_values(\"Interaction_score\", ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31db990e",
   "metadata": {},
   "source": [
    "Looking at the results, we now have a lot of unpopular tags with high interaction scores. Unfortunately this isn't a good metric either, as it naturally punishes popular tags and those that have lots of possible distinct pairings. For a broad topic like python, there are plenty of tags that are related and hence the score for each pairing is never going to approach 100 regardless of how intertwined the topics are. \n",
    "\n",
    "In addition, including pairings with a small number of occurences can be problematic. It is possible that the user posting a question isn't familiar with the correct tags to use, resulting in incorrect pairings in some cases. For popular tags, these mistakes shouldn't be too influential but for others we could end up with an interaction score of 100 for a nonsensical pairing of tags. \n",
    "\n",
    "A compromise is to filter results to a minimum number of questions that a pair appeared in. This should help reduce the noise but goes against the new metric's aim to allow unpopular tags a chance. This should still be an improvement over the previous metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8a69558",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions_with_both</th>\n",
       "      <th>Tag_1</th>\n",
       "      <th>Tag_2</th>\n",
       "      <th>Tag_1_Count</th>\n",
       "      <th>Tag_2_Count</th>\n",
       "      <th>Interaction_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dqn reinforcement-learning</th>\n",
       "      <td>34</td>\n",
       "      <td>dqn</td>\n",
       "      <td>reinforcement-learning</td>\n",
       "      <td>36</td>\n",
       "      <td>203</td>\n",
       "      <td>94.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q-learning reinforcement-learning</th>\n",
       "      <td>33</td>\n",
       "      <td>q-learning</td>\n",
       "      <td>reinforcement-learning</td>\n",
       "      <td>37</td>\n",
       "      <td>203</td>\n",
       "      <td>89.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policy-gradients reinforcement-learning</th>\n",
       "      <td>24</td>\n",
       "      <td>policy-gradients</td>\n",
       "      <td>reinforcement-learning</td>\n",
       "      <td>27</td>\n",
       "      <td>203</td>\n",
       "      <td>88.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deep-learning deep-network</th>\n",
       "      <td>22</td>\n",
       "      <td>deep-learning</td>\n",
       "      <td>deep-network</td>\n",
       "      <td>1220</td>\n",
       "      <td>29</td>\n",
       "      <td>75.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataframe pandas</th>\n",
       "      <td>60</td>\n",
       "      <td>dataframe</td>\n",
       "      <td>pandas</td>\n",
       "      <td>81</td>\n",
       "      <td>354</td>\n",
       "      <td>74.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forecast time-series</th>\n",
       "      <td>25</td>\n",
       "      <td>forecast</td>\n",
       "      <td>time-series</td>\n",
       "      <td>34</td>\n",
       "      <td>466</td>\n",
       "      <td>73.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forecasting time-series</th>\n",
       "      <td>59</td>\n",
       "      <td>forecasting</td>\n",
       "      <td>time-series</td>\n",
       "      <td>85</td>\n",
       "      <td>466</td>\n",
       "      <td>69.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pandas python</th>\n",
       "      <td>244</td>\n",
       "      <td>pandas</td>\n",
       "      <td>python</td>\n",
       "      <td>354</td>\n",
       "      <td>1814</td>\n",
       "      <td>68.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataframe python</th>\n",
       "      <td>51</td>\n",
       "      <td>dataframe</td>\n",
       "      <td>python</td>\n",
       "      <td>81</td>\n",
       "      <td>1814</td>\n",
       "      <td>62.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nlp nltk</th>\n",
       "      <td>27</td>\n",
       "      <td>nlp</td>\n",
       "      <td>nltk</td>\n",
       "      <td>493</td>\n",
       "      <td>43</td>\n",
       "      <td>62.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine-learning machine-learning-model</th>\n",
       "      <td>139</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>machine-learning-model</td>\n",
       "      <td>2693</td>\n",
       "      <td>224</td>\n",
       "      <td>62.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numpy python</th>\n",
       "      <td>71</td>\n",
       "      <td>numpy</td>\n",
       "      <td>python</td>\n",
       "      <td>117</td>\n",
       "      <td>1814</td>\n",
       "      <td>60.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python scipy</th>\n",
       "      <td>24</td>\n",
       "      <td>python</td>\n",
       "      <td>scipy</td>\n",
       "      <td>1814</td>\n",
       "      <td>40</td>\n",
       "      <td>60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clustering k-means</th>\n",
       "      <td>48</td>\n",
       "      <td>clustering</td>\n",
       "      <td>k-means</td>\n",
       "      <td>257</td>\n",
       "      <td>81</td>\n",
       "      <td>59.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opencv python</th>\n",
       "      <td>23</td>\n",
       "      <td>opencv</td>\n",
       "      <td>python</td>\n",
       "      <td>39</td>\n",
       "      <td>1814</td>\n",
       "      <td>58.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matplotlib python</th>\n",
       "      <td>45</td>\n",
       "      <td>matplotlib</td>\n",
       "      <td>python</td>\n",
       "      <td>77</td>\n",
       "      <td>1814</td>\n",
       "      <td>58.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kaggle machine-learning</th>\n",
       "      <td>24</td>\n",
       "      <td>kaggle</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>43</td>\n",
       "      <td>2693</td>\n",
       "      <td>55.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lstm rnn</th>\n",
       "      <td>82</td>\n",
       "      <td>lstm</td>\n",
       "      <td>rnn</td>\n",
       "      <td>402</td>\n",
       "      <td>149</td>\n",
       "      <td>55.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu tensorflow</th>\n",
       "      <td>23</td>\n",
       "      <td>gpu</td>\n",
       "      <td>tensorflow</td>\n",
       "      <td>42</td>\n",
       "      <td>584</td>\n",
       "      <td>54.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert nlp</th>\n",
       "      <td>35</td>\n",
       "      <td>bert</td>\n",
       "      <td>nlp</td>\n",
       "      <td>64</td>\n",
       "      <td>493</td>\n",
       "      <td>54.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>backpropagation neural-network</th>\n",
       "      <td>34</td>\n",
       "      <td>backpropagation</td>\n",
       "      <td>neural-network</td>\n",
       "      <td>65</td>\n",
       "      <td>1055</td>\n",
       "      <td>52.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activation-function neural-network</th>\n",
       "      <td>23</td>\n",
       "      <td>activation-function</td>\n",
       "      <td>neural-network</td>\n",
       "      <td>44</td>\n",
       "      <td>1055</td>\n",
       "      <td>52.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine-learning supervised-learning</th>\n",
       "      <td>40</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>supervised-learning</td>\n",
       "      <td>2693</td>\n",
       "      <td>82</td>\n",
       "      <td>48.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neural-network recurrent-neural-net</th>\n",
       "      <td>44</td>\n",
       "      <td>neural-network</td>\n",
       "      <td>recurrent-neural-net</td>\n",
       "      <td>1055</td>\n",
       "      <td>91</td>\n",
       "      <td>48.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k-nn machine-learning</th>\n",
       "      <td>24</td>\n",
       "      <td>k-nn</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>50</td>\n",
       "      <td>2693</td>\n",
       "      <td>48.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Questions_with_both  \\\n",
       "dqn reinforcement-learning                                34   \n",
       "q-learning reinforcement-learning                         33   \n",
       "policy-gradients reinforcement-learning                   24   \n",
       "deep-learning deep-network                                22   \n",
       "dataframe pandas                                          60   \n",
       "forecast time-series                                      25   \n",
       "forecasting time-series                                   59   \n",
       "pandas python                                            244   \n",
       "dataframe python                                          51   \n",
       "nlp nltk                                                  27   \n",
       "machine-learning machine-learning-model                  139   \n",
       "numpy python                                              71   \n",
       "python scipy                                              24   \n",
       "clustering k-means                                        48   \n",
       "opencv python                                             23   \n",
       "matplotlib python                                         45   \n",
       "kaggle machine-learning                                   24   \n",
       "lstm rnn                                                  82   \n",
       "gpu tensorflow                                            23   \n",
       "bert nlp                                                  35   \n",
       "backpropagation neural-network                            34   \n",
       "activation-function neural-network                        23   \n",
       "machine-learning supervised-learning                      40   \n",
       "neural-network recurrent-neural-net                       44   \n",
       "k-nn machine-learning                                     24   \n",
       "\n",
       "                                                       Tag_1  \\\n",
       "dqn reinforcement-learning                               dqn   \n",
       "q-learning reinforcement-learning                 q-learning   \n",
       "policy-gradients reinforcement-learning     policy-gradients   \n",
       "deep-learning deep-network                     deep-learning   \n",
       "dataframe pandas                                   dataframe   \n",
       "forecast time-series                                forecast   \n",
       "forecasting time-series                          forecasting   \n",
       "pandas python                                         pandas   \n",
       "dataframe python                                   dataframe   \n",
       "nlp nltk                                                 nlp   \n",
       "machine-learning machine-learning-model     machine-learning   \n",
       "numpy python                                           numpy   \n",
       "python scipy                                          python   \n",
       "clustering k-means                                clustering   \n",
       "opencv python                                         opencv   \n",
       "matplotlib python                                 matplotlib   \n",
       "kaggle machine-learning                               kaggle   \n",
       "lstm rnn                                                lstm   \n",
       "gpu tensorflow                                           gpu   \n",
       "bert nlp                                                bert   \n",
       "backpropagation neural-network               backpropagation   \n",
       "activation-function neural-network       activation-function   \n",
       "machine-learning supervised-learning        machine-learning   \n",
       "neural-network recurrent-neural-net           neural-network   \n",
       "k-nn machine-learning                                   k-nn   \n",
       "\n",
       "                                                          Tag_2  Tag_1_Count  \\\n",
       "dqn reinforcement-learning               reinforcement-learning           36   \n",
       "q-learning reinforcement-learning        reinforcement-learning           37   \n",
       "policy-gradients reinforcement-learning  reinforcement-learning           27   \n",
       "deep-learning deep-network                         deep-network         1220   \n",
       "dataframe pandas                                         pandas           81   \n",
       "forecast time-series                                time-series           34   \n",
       "forecasting time-series                             time-series           85   \n",
       "pandas python                                            python          354   \n",
       "dataframe python                                         python           81   \n",
       "nlp nltk                                                   nltk          493   \n",
       "machine-learning machine-learning-model  machine-learning-model         2693   \n",
       "numpy python                                             python          117   \n",
       "python scipy                                              scipy         1814   \n",
       "clustering k-means                                      k-means          257   \n",
       "opencv python                                            python           39   \n",
       "matplotlib python                                        python           77   \n",
       "kaggle machine-learning                        machine-learning           43   \n",
       "lstm rnn                                                    rnn          402   \n",
       "gpu tensorflow                                       tensorflow           42   \n",
       "bert nlp                                                    nlp           64   \n",
       "backpropagation neural-network                   neural-network           65   \n",
       "activation-function neural-network               neural-network           44   \n",
       "machine-learning supervised-learning        supervised-learning         2693   \n",
       "neural-network recurrent-neural-net        recurrent-neural-net         1055   \n",
       "k-nn machine-learning                          machine-learning           50   \n",
       "\n",
       "                                         Tag_2_Count  Interaction_score  \n",
       "dqn reinforcement-learning                       203              94.44  \n",
       "q-learning reinforcement-learning                203              89.19  \n",
       "policy-gradients reinforcement-learning          203              88.89  \n",
       "deep-learning deep-network                        29              75.86  \n",
       "dataframe pandas                                 354              74.07  \n",
       "forecast time-series                             466              73.53  \n",
       "forecasting time-series                          466              69.41  \n",
       "pandas python                                   1814              68.93  \n",
       "dataframe python                                1814              62.96  \n",
       "nlp nltk                                          43              62.79  \n",
       "machine-learning machine-learning-model          224              62.05  \n",
       "numpy python                                    1814              60.68  \n",
       "python scipy                                      40              60.00  \n",
       "clustering k-means                                81              59.26  \n",
       "opencv python                                   1814              58.97  \n",
       "matplotlib python                               1814              58.44  \n",
       "kaggle machine-learning                         2693              55.81  \n",
       "lstm rnn                                         149              55.03  \n",
       "gpu tensorflow                                   584              54.76  \n",
       "bert nlp                                         493              54.69  \n",
       "backpropagation neural-network                  1055              52.31  \n",
       "activation-function neural-network              1055              52.27  \n",
       "machine-learning supervised-learning              82              48.78  \n",
       "neural-network recurrent-neural-net               91              48.35  \n",
       "k-nn machine-learning                           2693              48.00  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter and sort the data based on the new criteria\n",
    "final_filtered = final[final.Questions_with_both > 20]\n",
    "final_filtered.sort_values(\"Interaction_score\", ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5911dd",
   "metadata": {},
   "source": [
    "These results are a little more varied in terms of tag popularity, but it still focuses mostly on less popular tags.\n",
    "\n",
    "Let's try combining the popularity of a tag with the current definition of interaction score. We take the average of two different metrics to get a final score, and filter out the very low frequency tags since they still dominate the top 25 under this new metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09c4524f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions_with_both</th>\n",
       "      <th>Tag_1</th>\n",
       "      <th>Tag_2</th>\n",
       "      <th>Tag_1_Count</th>\n",
       "      <th>Tag_2_Count</th>\n",
       "      <th>Interaction_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>machine-learning python</th>\n",
       "      <td>499</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>python</td>\n",
       "      <td>2693</td>\n",
       "      <td>1814</td>\n",
       "      <td>63.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deep-learning machine-learning</th>\n",
       "      <td>429</td>\n",
       "      <td>deep-learning</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>1220</td>\n",
       "      <td>2693</td>\n",
       "      <td>60.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pandas python</th>\n",
       "      <td>244</td>\n",
       "      <td>pandas</td>\n",
       "      <td>python</td>\n",
       "      <td>354</td>\n",
       "      <td>1814</td>\n",
       "      <td>58.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine-learning neural-network</th>\n",
       "      <td>366</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>neural-network</td>\n",
       "      <td>2693</td>\n",
       "      <td>1055</td>\n",
       "      <td>54.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dqn reinforcement-learning</th>\n",
       "      <td>34</td>\n",
       "      <td>dqn</td>\n",
       "      <td>reinforcement-learning</td>\n",
       "      <td>36</td>\n",
       "      <td>203</td>\n",
       "      <td>50.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orange orange3</th>\n",
       "      <td>19</td>\n",
       "      <td>orange</td>\n",
       "      <td>orange3</td>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "      <td>49.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q-learning reinforcement-learning</th>\n",
       "      <td>33</td>\n",
       "      <td>q-learning</td>\n",
       "      <td>reinforcement-learning</td>\n",
       "      <td>37</td>\n",
       "      <td>203</td>\n",
       "      <td>47.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keras tensorflow</th>\n",
       "      <td>256</td>\n",
       "      <td>keras</td>\n",
       "      <td>tensorflow</td>\n",
       "      <td>935</td>\n",
       "      <td>584</td>\n",
       "      <td>47.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>policy-gradients reinforcement-learning</th>\n",
       "      <td>24</td>\n",
       "      <td>policy-gradients</td>\n",
       "      <td>reinforcement-learning</td>\n",
       "      <td>27</td>\n",
       "      <td>203</td>\n",
       "      <td>46.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python scikit-learn</th>\n",
       "      <td>235</td>\n",
       "      <td>python</td>\n",
       "      <td>scikit-learn</td>\n",
       "      <td>1814</td>\n",
       "      <td>540</td>\n",
       "      <td>45.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deep-learning neural-network</th>\n",
       "      <td>305</td>\n",
       "      <td>deep-learning</td>\n",
       "      <td>neural-network</td>\n",
       "      <td>1220</td>\n",
       "      <td>1055</td>\n",
       "      <td>45.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine-learning machine-learning-model</th>\n",
       "      <td>139</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>machine-learning-model</td>\n",
       "      <td>2693</td>\n",
       "      <td>224</td>\n",
       "      <td>44.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classification machine-learning</th>\n",
       "      <td>259</td>\n",
       "      <td>classification</td>\n",
       "      <td>machine-learning</td>\n",
       "      <td>685</td>\n",
       "      <td>2693</td>\n",
       "      <td>44.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actor-critic reinforcement-learning</th>\n",
       "      <td>18</td>\n",
       "      <td>actor-critic</td>\n",
       "      <td>reinforcement-learning</td>\n",
       "      <td>21</td>\n",
       "      <td>203</td>\n",
       "      <td>44.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nlp spacy</th>\n",
       "      <td>17</td>\n",
       "      <td>nlp</td>\n",
       "      <td>spacy</td>\n",
       "      <td>493</td>\n",
       "      <td>20</td>\n",
       "      <td>44.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataframe pandas</th>\n",
       "      <td>60</td>\n",
       "      <td>dataframe</td>\n",
       "      <td>pandas</td>\n",
       "      <td>81</td>\n",
       "      <td>354</td>\n",
       "      <td>43.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keras python</th>\n",
       "      <td>280</td>\n",
       "      <td>keras</td>\n",
       "      <td>python</td>\n",
       "      <td>935</td>\n",
       "      <td>1814</td>\n",
       "      <td>43.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forecasting time-series</th>\n",
       "      <td>59</td>\n",
       "      <td>forecasting</td>\n",
       "      <td>time-series</td>\n",
       "      <td>85</td>\n",
       "      <td>466</td>\n",
       "      <td>40.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deep-learning deep-network</th>\n",
       "      <td>22</td>\n",
       "      <td>deep-learning</td>\n",
       "      <td>deep-network</td>\n",
       "      <td>1220</td>\n",
       "      <td>29</td>\n",
       "      <td>40.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>descriptive-statistics statistics</th>\n",
       "      <td>16</td>\n",
       "      <td>descriptive-statistics</td>\n",
       "      <td>statistics</td>\n",
       "      <td>21</td>\n",
       "      <td>234</td>\n",
       "      <td>39.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forecast time-series</th>\n",
       "      <td>25</td>\n",
       "      <td>forecast</td>\n",
       "      <td>time-series</td>\n",
       "      <td>34</td>\n",
       "      <td>466</td>\n",
       "      <td>39.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deep-learning keras</th>\n",
       "      <td>247</td>\n",
       "      <td>deep-learning</td>\n",
       "      <td>keras</td>\n",
       "      <td>1220</td>\n",
       "      <td>935</td>\n",
       "      <td>37.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r rstudio</th>\n",
       "      <td>11</td>\n",
       "      <td>r</td>\n",
       "      <td>rstudio</td>\n",
       "      <td>268</td>\n",
       "      <td>15</td>\n",
       "      <td>37.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numpy python</th>\n",
       "      <td>71</td>\n",
       "      <td>numpy</td>\n",
       "      <td>python</td>\n",
       "      <td>117</td>\n",
       "      <td>1814</td>\n",
       "      <td>37.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clustering dbscan</th>\n",
       "      <td>13</td>\n",
       "      <td>clustering</td>\n",
       "      <td>dbscan</td>\n",
       "      <td>257</td>\n",
       "      <td>18</td>\n",
       "      <td>37.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Questions_with_both  \\\n",
       "machine-learning python                                  499   \n",
       "deep-learning machine-learning                           429   \n",
       "pandas python                                            244   \n",
       "machine-learning neural-network                          366   \n",
       "dqn reinforcement-learning                                34   \n",
       "orange orange3                                            19   \n",
       "q-learning reinforcement-learning                         33   \n",
       "keras tensorflow                                         256   \n",
       "policy-gradients reinforcement-learning                   24   \n",
       "python scikit-learn                                      235   \n",
       "deep-learning neural-network                             305   \n",
       "machine-learning machine-learning-model                  139   \n",
       "classification machine-learning                          259   \n",
       "actor-critic reinforcement-learning                       18   \n",
       "nlp spacy                                                 17   \n",
       "dataframe pandas                                          60   \n",
       "keras python                                             280   \n",
       "forecasting time-series                                   59   \n",
       "deep-learning deep-network                                22   \n",
       "descriptive-statistics statistics                         16   \n",
       "forecast time-series                                      25   \n",
       "deep-learning keras                                      247   \n",
       "r rstudio                                                 11   \n",
       "numpy python                                              71   \n",
       "clustering dbscan                                         13   \n",
       "\n",
       "                                                          Tag_1  \\\n",
       "machine-learning python                        machine-learning   \n",
       "deep-learning machine-learning                    deep-learning   \n",
       "pandas python                                            pandas   \n",
       "machine-learning neural-network                machine-learning   \n",
       "dqn reinforcement-learning                                  dqn   \n",
       "orange orange3                                           orange   \n",
       "q-learning reinforcement-learning                    q-learning   \n",
       "keras tensorflow                                          keras   \n",
       "policy-gradients reinforcement-learning        policy-gradients   \n",
       "python scikit-learn                                      python   \n",
       "deep-learning neural-network                      deep-learning   \n",
       "machine-learning machine-learning-model        machine-learning   \n",
       "classification machine-learning                  classification   \n",
       "actor-critic reinforcement-learning                actor-critic   \n",
       "nlp spacy                                                   nlp   \n",
       "dataframe pandas                                      dataframe   \n",
       "keras python                                              keras   \n",
       "forecasting time-series                             forecasting   \n",
       "deep-learning deep-network                        deep-learning   \n",
       "descriptive-statistics statistics        descriptive-statistics   \n",
       "forecast time-series                                   forecast   \n",
       "deep-learning keras                               deep-learning   \n",
       "r rstudio                                                     r   \n",
       "numpy python                                              numpy   \n",
       "clustering dbscan                                    clustering   \n",
       "\n",
       "                                                          Tag_2  Tag_1_Count  \\\n",
       "machine-learning python                                  python         2693   \n",
       "deep-learning machine-learning                 machine-learning         1220   \n",
       "pandas python                                            python          354   \n",
       "machine-learning neural-network                  neural-network         2693   \n",
       "dqn reinforcement-learning               reinforcement-learning           36   \n",
       "orange orange3                                          orange3           64   \n",
       "q-learning reinforcement-learning        reinforcement-learning           37   \n",
       "keras tensorflow                                     tensorflow          935   \n",
       "policy-gradients reinforcement-learning  reinforcement-learning           27   \n",
       "python scikit-learn                                scikit-learn         1814   \n",
       "deep-learning neural-network                     neural-network         1220   \n",
       "machine-learning machine-learning-model  machine-learning-model         2693   \n",
       "classification machine-learning                machine-learning          685   \n",
       "actor-critic reinforcement-learning      reinforcement-learning           21   \n",
       "nlp spacy                                                 spacy          493   \n",
       "dataframe pandas                                         pandas           81   \n",
       "keras python                                             python          935   \n",
       "forecasting time-series                             time-series           85   \n",
       "deep-learning deep-network                         deep-network         1220   \n",
       "descriptive-statistics statistics                    statistics           21   \n",
       "forecast time-series                                time-series           34   \n",
       "deep-learning keras                                       keras         1220   \n",
       "r rstudio                                               rstudio          268   \n",
       "numpy python                                             python          117   \n",
       "clustering dbscan                                        dbscan          257   \n",
       "\n",
       "                                         Tag_2_Count  Interaction_score  \n",
       "machine-learning python                         1814              63.75  \n",
       "deep-learning machine-learning                  2693              60.57  \n",
       "pandas python                                   1814              58.91  \n",
       "machine-learning neural-network                 1055              54.02  \n",
       "dqn reinforcement-learning                       203              50.63  \n",
       "orange orange3                                    20              49.40  \n",
       "q-learning reinforcement-learning                203              47.90  \n",
       "keras tensorflow                                 584              47.57  \n",
       "policy-gradients reinforcement-learning          203              46.85  \n",
       "python scikit-learn                              540              45.31  \n",
       "deep-learning neural-network                    1055              45.02  \n",
       "machine-learning machine-learning-model          224              44.95  \n",
       "classification machine-learning                 2693              44.86  \n",
       "actor-critic reinforcement-learning              203              44.66  \n",
       "nlp spacy                                         20              44.20  \n",
       "dataframe pandas                                 354              43.05  \n",
       "keras python                                    1814              43.03  \n",
       "forecasting time-series                          466              40.62  \n",
       "deep-learning deep-network                        29              40.14  \n",
       "descriptive-statistics statistics                234              39.70  \n",
       "forecast time-series                             466              39.27  \n",
       "deep-learning keras                              935              37.96  \n",
       "r rstudio                                         15              37.77  \n",
       "numpy python                                    1814              37.46  \n",
       "clustering dbscan                                 18              37.41  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def int_scorer(row):\n",
    "    count = np.min([row[\"Tag_1_Count\"], row[\"Tag_2_Count\"]])\n",
    "    int_score = 100 * row[\"Questions_with_both\"] / count\n",
    "    pop_score = 100 * row[\"Questions_with_both\"] / final.Questions_with_both.max()\n",
    "    score = np.mean([int_score, pop_score])\n",
    "    return round(score, 2)\n",
    "\n",
    "# Generate the new scores\n",
    "final[\"Interaction_score\"] = final.apply(int_scorer, axis=1)\n",
    "\n",
    "# Filter and sort the results\n",
    "final_filtered = final[final.Questions_with_both > 10]\n",
    "final_filtered.sort_values(\"Interaction_score\", ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f9de5e",
   "metadata": {},
   "source": [
    "These results look a lot fairer in terms of tag popularity. While not all tags are self-explanatory, pretty much all of the top 25 pairs look quite related under this new metric. It's unlikely we can create a perfect absolute ordering of tag relations, but this looks good enough to quickly find some strong relationships.\n",
    "\n",
    "This is where we will leave things for now in terms of metric choices. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcdd48b",
   "metadata": {},
   "source": [
    "## Visualising Tag Relationships\n",
    "\n",
    "From here we want to be able to quickly create visualisations of the top N related tags for any given tag. This could be useful to quickly sample a bunch of related topics for an unknown tag. We also want to be able to change the filtering strength, since we may need to include unpopular tags when investigating other rare tags.\n",
    "\n",
    "We begin by setting up the seaborn style that we want to use. The next issue is yet again related to the format of tags in our dataframe. Each tag can appear in either of the individual tag columns on each row, stopping us from plotting a single column directly against *Interaction_score*. We can run a quick function through the data to swap all instances of a particular tag into the same column. \n",
    "\n",
    "Along with this formatting we can do some filtering based on the number of related tags that we want, and the strength of the popularity filtering. After all of this we get a nice and easy dataframe to plot with seaborn to wrap things up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c62d03e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style and colour scheme\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_palette(\"Paired\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad60158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to ensure a given tag is in Tag_1 column for each row\n",
    "def tag_switch(row, tag_):\n",
    "    if row[\"Tag_2\"] == tag_:\n",
    "        row[\"Tag_2\"] = row[\"Tag_1\"]\n",
    "        row[\"Tag_1\"] = tag_\n",
    "    return row\n",
    "\n",
    "# Plot the best pairings for a particular tag with given filters\n",
    "def plot_relations(df, tag, filter_strength=10, num=10):\n",
    "    \n",
    "    # Replace any spaces with dashes to match the format of the data, allowing simpler function use\n",
    "    given_tag = tag\n",
    "    tag = tag.replace(\" \", \"-\")\n",
    "    \n",
    "    # Check that the tag actually exists in the data\n",
    "    unique_tags = set(df[\"Tag_1\"].unique()).union(set(df[\"Tag_2\"].unique()))\n",
    "    if tag not in unique_tags:\n",
    "        print(f\"{given_tag} not found in data.\")\n",
    "        return\n",
    "    \n",
    "    # Apply filtering to the data to remove low-frequency pairs\n",
    "    df = df[df.Questions_with_both > filter_strength]\n",
    "    df = df[(df[\"Tag_1\"]==tag)|(df[\"Tag_2\"]==tag)].sort_values(\"Interaction_score\", ascending=False)\n",
    "    \n",
    "    # Restrict the results to the requested or default number\n",
    "    num = min(num, len(df))\n",
    "    if num == 0:\n",
    "        print(f\"{given_tag} not found in filtered data, try a weaker filter.\")\n",
    "        return\n",
    "    \n",
    "    # Re-organise the tag columns to allow easier plotting for this tag\n",
    "    df = df.apply(tag_switch, args=(tag,), axis=1)\n",
    "    \n",
    "    # Plot and label the results\n",
    "    g = sns.catplot(kind=\"bar\", x=\"Interaction_score\", y=\"Tag_2\", data=df.head(num))\n",
    "    g.set(ylabel=\"\", xlabel=\"Strength of Relationship\")\n",
    "    g.fig.suptitle(f\"Top {num} closely related question tags to $\\it{given_tag}$\")\n",
    "    g.tight_layout()\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba178971",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example use of the plotting function\n",
    "plot_relations(final, \"python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2096a006",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    " \n",
    "Looks good! We can now use this function to find some closely related tags for any tag that exists in the sampled data. We could perform some additional plot formatting to improve the look, but this is better to do case by case since the plots can be so different. \n",
    "\n",
    "Could also consider using some sort of regex or string similarity to allow easier entry of tags in the final plotting function, rather than requiring a perfect match which may be based on a certain standard set by Stack Exchange that isn't universal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
